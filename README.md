# Legal Document Retrieval using Deep Learning methods

A sophisticated legal document retrieval system using Deep Learning methods to understand complex Vietnamese legal document relationships. The system implements two complementary approaches: knowledge distillation and GNN-based reranking.

## ğŸ¯ Project Overview

This project addresses legal document retrieval using the VLegalKMaps dataset (Vietnamese legal knowledge graphs). The system processes legal documents stored as RDF/Turtle graphs and retrieves relevant document chunks based on natural language queries.

### Key Features
- **Legal Document Processing**: Handles Vietnamese legal documents with complex hierarchical structures
- **Graph Neural Networks**: Uses Heterogeneous Graph Transformers (HGT) for legal document understanding
- **Knowledge Distillation**: Implements teacher-student training for improved embeddings

## ğŸ—ï¸ System Architecture

### Approach 1: Knowledge Distillation Pipeline
A 5-round teacher-student distillation process:
- **Round 1**: Train embedder on gold data â†’ train cross-encoder on gold labels
- **Rounds 2-3**: Teacher-guided training using cross-encoder generated labels
- **Rounds 4-5**: Self-improvement using embedder scores as pseudo-labels

### Approach 2: GNN-based Reranking (Primary Focus)
1. **Vector Search**: FAISS-based retrieval of candidate document chunks
2. **Graph Construction**: Builds heterogeneous legal graphs from retrieved candidates
3. **GNN Reranking**: Uses Heterogeneous Graph Transformers:
   - **DualReranker**: Combines local and global graph representations

## ğŸ“ Project Structure

```
AI7102-Project/
â”œâ”€â”€ src/                          # Main source code
â”‚   â”œâ”€â”€ build_faiss.py           # FAISS vector database builder
â”‚   â”œâ”€â”€ helper.py                # Utility functions and helpers
â”‚   â”œâ”€â”€ synthesis/               # Data synthesis and dataset creation
â”‚   â”‚   â”œâ”€â”€ classifier.py       # Node classification for legal documents
â”‚   â”‚   â”œâ”€â”€ data_loader.py      # Knowledge graph data loading
â”‚   â”‚   â”œâ”€â”€ generator.py        # Question generation from legal graphs
â”‚   â”‚   â””â”€â”€ prompt.py           # Prompt templates for LLM-based generation
â”‚   â”œâ”€â”€ training/                # Training and model development
â”‚   â”‚   â”œâ”€â”€ base_distill.py      # Knowledge distillation pipeline
â”‚   â”‚   â”œâ”€â”€ dataset.py          # Dataset creation for GNN training
â”‚   â”‚   â”œâ”€â”€ loss.py             # Loss functions for reranking
â”‚   â”‚   â”œâ”€â”€ splits.py           # Train/validation/test splitting
â”‚   â”‚   â”œâ”€â”€ train.py            # Main training script
â”‚   â”‚   â”œâ”€â”€ train_loop.py       # Training loop implementation
â”‚   â”‚   â””â”€â”€ train_utils.py      # Training utilities and evaluation
â”‚   â”œâ”€â”€ models/                  # Neural network models
â”‚   â”‚   â”œâ”€â”€ hgt.py              # Heterogeneous Graph Transformer (HGT)
â”‚   â”‚   â”œâ”€â”€ pool.py             # Pooling mechanisms
â”‚   â”‚   â”œâ”€â”€ reranker.py         # GNN reranker implementation
â”‚   â”‚   â””â”€â”€ reranker2.py        # Dual reranker variant
â”‚   â””â”€â”€ create_graph/           # Graph construction utilities
â”‚       â”œâ”€â”€ create_graph.py     # Main graph builder
â”‚       â”œâ”€â”€ graph_utils.py      # Graph construction utilities
â”‚       â”œâ”€â”€ rdf_utils.py        # RDF/Turtle utilities
â”‚       â””â”€â”€ store.py            # Graph storage management
â”œâ”€â”€ dataset/                     # Core dataset and processed data files
â”‚   â”œâ”€â”€ dataset.jsonl           # Synthetic questions with ground truth URIs for training/evaluation
â”‚   â”œâ”€â”€ splits.json             # Train/validation/test splits for reproducible experiments
â”‚   â”œâ”€â”€ legal_graphs/           # Pre-computed heterogeneous graphs for GNN training (offline processing)
â”‚   â”œâ”€â”€ vectordb_files/         # FAISS vector database and document metadata
â”‚   â”‚   â”œâ”€â”€ database.pkl      # All leaf nodes with text content and corresponding URIs
â”‚   â”‚   â””â”€â”€ vectordb.bin      # FAISS index for fast similarity search of legal documents
â”‚   â”œâ”€â”€ ttldataAJZ/             # Vietnamese legal documents - AJZ category (RDF/Turtle format)
â”‚   â”œâ”€â”€ ttldataDEC/             # Vietnamese legal documents - DEC category (Decrees, RDF/Turtle format)
â”‚   â””â”€â”€ ttldataDOC/             # Vietnamese legal documents - DOC category (Documents, RDF/Turtle format)
â”œâ”€â”€ weight/                      # Trained model weights
â”œâ”€â”€ pyproject.toml               # Project configuration and dependencies
â””â”€â”€ requirements.txt             # Full dependency list
```

## ğŸš€ Quick Start

### Installation

Using `uv` (recommended):
```bash
# Clone the repository
git clone <repository-url>
cd AI7102-project

# Install dependencies
uv sync
```

Using `pip`:
```bash
pip install -r requirements.txt
```

### Data Setup

1. **Download Legal Dataset**: Download the data from https://aseados.ucd.ie/vlegal/download/. Place Vietnamese legal documents (.ttl files) in `dataset/` folder
2. **Generate Training Questions**:
   ```bash
   python -m src.synthesis.generator \
       --data-root dataset/ttldataAJZ \
       --outfile dataset/dataset.jsonl \
       --per-phase 10 \
       --model qwen2.5-7b-instruct
   ```
3. **Build Vector Database**:
   ```bash
   python -m src.build_faiss
   ```

### Training

#### Base Retriever (Traditional Embedding-based)
```bash
python -m src.training.train --task base_retr
```

#### GNN Reranking Approaches
```bash

# Dual GNN reranking (recommended)
python -m src.training.train --task gnn_dual
```

#### Knowledge Distillation
```bash

# For common models
python -m src.training.train --task base_teacher

# For bge-m3
python -m src.training.train --task bge_teacher
```

### Graph Construction for GNN Training
```bash
python -m src.create_graph.create_graph \
    --dataset-file dataset/dataset.jsonl \
    --max-samples 1000 \
    --max-cands 50 \
    --out-dir dataset/legal_graphs
```

## ğŸ”§ Key Components Explained

### Data Pipeline (`src/synthesis/`)

**`generator.py`**: Generates synthetic training questions from legal knowledge graphs in three phases:
- **Phase 1**: Content node questions from leaf nodes
- **Phase 2**: Structural questions from document articles
- **Phase 3**: Cross-document questions from connected documents

**`classifier.py`**: Classifies legal document nodes into:
- **Content Nodes**: Main leaf nodes containing legal text
- **Pointer Nodes**: Nodes indicating document relationships (replacement, amendment, citation)
- **Structural Nodes**: Non-leaf hierarchical nodes

### Graph Construction (`src/create_graph/`)

**`create_graph.py`**: Offline graph builder that:
1. Retrieves candidate nodes using FAISS vector search
2. Constructs local graphs for each candidate (full document tree + 1-hop documents)
3. Builds global graphs by combining all local graphs
4. Stores graphs with pre-computed BERT embeddings

**Graph Types**:
- **Local Graphs**: Complete document hierarchy + related documents for each candidate
- **Global Graph**: Union of all local graphs with inter-document connections

### Training Pipeline (`src/training/`)

**`train.py`**: Main training entry point supporting multiple approaches:
- `base_retr`: Traditional embedding-based retrieval
- `gnn_dual`: Dual reranking with local and global graphs
- `base_teacher`: Teacher-student knowledge distillation
- `bge_teacher`: Teacher-student knowledge distillation for BGE-M3

**`base_distill.py`**: 5-round knowledge distillation implementing iterative improvement through teacher-student training and self-supervision.
